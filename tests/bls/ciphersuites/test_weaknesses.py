from itertools import combinations, count, islice
from math import sqrt
import numpy

from py_ecc.bls import G2ProofOfPossession as bls
from py_ecc.bls.g2_primitives import *
from py_ecc.optimized_bls12_381.optimized_curve import *
from py_ecc.bls.hash_to_curve import hash_to_G2
from hashlib import sha256
from timeit import default_timer as timer

import structlog

log = structlog.get_logger()


def primes(n):
    """ Returns  a list of primes < n """
    sieve = [True] * n
    for i in range(3, int(n ** 0.5) + 1, 2):
        if sieve[i]:
            sieve[i * i:: 2 * i] = [False] * ((n - i * i - 1) // (2 * i) + 1)
    return [2] + [i for i in range(3, n, 2) if sieve[i]]


def is_prime(n):
    return n > 1 and all(n % i for i in islice(count(2), int(sqrt(n) - 1)))


def test_partition_of_unity():
    """
    This test shows a weakness in bls.FastAggregateVerify, when private keys are a partition to 1 (1 = sk_0 + .... +
    sk_n % curve_order, with the special case private_key = 1 mod curve_order). If priv_key = 1, anyone can create a
    signature of a messages (withdrawal, slashable casper proposals, etc...) For the general case, under specific
    circumstances, an attacker (for instance, a malicious aggregator) can observe and analyze traffic,
    to create universal forgeries of the aggregated signatures of a subset of validators in the future. In practice,
    for a set of validators in a committee, who's private_keys sum up to 1. If this is the case can be detected by an
    attacker without knowledge of any private keys, by analyzing p2p traffic for the property bls.Aggregate([sig0,
    ..., sign] == message_hash. The likelihood of a partition to be observable in the wild depends on the size of the
    validator set and p(1), the number of possible partitions of 1 % curve_order. This likelihood is currently being
    reviewed. For reference: https://doi.org/10.2307/1993300
    """

    # boilerplate
    m = b"message"

    # private key is the multiplicative identity element
    sk0 = 1

    sk1 = 2880067194370816120
    sk2 = 354224848179261915075
    DST = b"BLS_SIG_BLS12381G2_XMD:SHA-256_SSWU_RO_POP_"

    # generating the message hash, a universally forgeable signature for a specific set of private keys
    message_hash = G2_to_signature(hash_to_G2(m, DST, hash_function=sha256))

    # BASE CASE: sk == 1

    one_key = G1_to_pubkey(G1)
    one_public_key = bls.SkToPk(sk0)
    # The public Key here is just the curve's generator
    assert one_key == one_public_key
    pk1 = bls.SkToPk(sk1)
    pk2 = bls.SkToPk(sk2)

    one_sigm = bls.Sign(sk0, m)

    # this is the bug allowing an attacker to create a universal forgery in the special case sk == 1
    assert one_sigm == message_hash
    sigm1 = bls.Sign(sk1, m)
    sigm2 = bls.Sign(sk2, m)

    log.msg(
        "If private key == 1 % curve_order, the signature is just the message hash and can be generated by anyone",
        verification_result=bls.FastAggregateVerify(
            [one_key, pk1, pk2], m, bls.Aggregate([message_hash, sigm1, sigm2])
        ),
    )

    # GENERAL CASE: 1 = sk_0 + .... + sk_n % curve_order

    def generate_additive_inverse(sk: int) -> list[int]:
        """
        For the PoC, we only create order 2 partitions (e.g. consisting of a private key and its additive inverses).
        In general any partition of order < MAX_VALIDATORS_PER_COMMITEE is viable in the context of eth2. The number
        of possible partitions of one % curve_order and therefore the likelihood of a partition to be observable by
        an attacker in the wild is currently being reviewed. For reference: https://doi.org/10.2307/1993300
        """
        additive_inverse = curve_order - sk + 1
        assert ((additive_inverse + sk) % curve_order) == 1
        return [sk, additive_inverse]

    private_keys = generate_additive_inverse(sk2)
    public_keys = [bls.SkToPk(priv_key) for priv_key in private_keys]
    signatures = [bls.Sign(priv_key, m) for priv_key in private_keys]
    assert len(public_keys) > 1
    assert len(signatures) > 1

    # check everything follows protocol
    for private_key in private_keys:
        assert bls._is_valid_privkey(private_key)
    for public_key in public_keys:
        assert bls._is_valid_pubkey(public_key)
    for signature in signatures:
        assert bls._is_valid_signature(signature)

    # this is the bug in the general case 1 = sk_0 + ... + sk_n, allowing an attacker to create a universal forgery
    # of a signature valid for FastAggregateVerify
    assert bls.Aggregate(signatures) == message_hash
    assert bls.FastAggregateVerify(public_keys, m, message_hash)
    assert not bls.AggregateVerify(public_keys, m, message_hash)

    log.msg(
        "For the general case, if 1 = (sk_0 + .... + sk_n) % curve_order, the aggregated signature is just the hash "
        "of the message and can be generated by anyone",
        verification_result=bls.FastAggregateVerify(public_keys, m, message_hash),
    )


def test_aggregated_pubkeys():
    sk0 = 1234
    sk1 = 1111
    # horcrux keys
    pk0 = bls.SkToPk(sk0)
    pk1 = bls.SkToPk(sk1)

    # aggregated_key
    pk01 = bls._AggregatePKs([pk0, pk1])
    sk01 = sk0 + sk1
    m = b"message"
    m0 = b"message0"
    m1 = b"message1"

    # one attestation/proposal for attestation/proposal data
    sig0 = bls.Sign(sk0, m)
    # another attestation for the same attestation/proposal data
    sig1 = bls.Sign(sk1, m)
    sigm0 = bls.Sign(sk0, m0)
    sigm1 = bls.Sign(sk1, m1)
    sig01 = bls.Sign(sk01, m)
    # Aggregator aggregates signatueres of pk0 and pk1
    aggregated_signature = bls.Aggregate([sig0, sig1])
    # happy case in a validator, get aggregated_signature from aggregator and verifies against
    # set of pkeys
    log.msg(
        "the happy case of an aggregated attestation, bls.FastAggregateVerify([pk0, pk1], m, aggregated_signature)=",
        verification_result=bls.FastAggregateVerify(
            [pk0, pk1], m, aggregated_signature
        ),
    )

    log.msg(
        "sk01 by pk34, bls.FastAggregateVerify([pk01], m, sig01)=",
        verification_result=bls.FastAggregateVerify([pk01], m, sig01),
    )
    log.msg(
        "sig01 == aggregated_signature ? Yes. So we can aggregate private keys and sign or "
        "aggregate the signatures will be the same. Yay, Pairing! "
        "sig01 == bls.Aggregate([sig0, sig1]=",
        verification_result=sig01 == bls.Aggregate([sig0, sig1]),
    )

    log.msg(
        "sk01 by pk0, pk1",
        verification_result=bls.FastAggregateVerify([pk0, pk1], m, sig01),
    )
    log.msg("sk01 by pk0", verification_result=bls.FastAggregateVerify([pk0], m, sig01))

    log.msg(
        "sig0, sig1 by pk01",
        verification_result=bls.FastAggregateVerify(
            [pk01], m, bls.Aggregate([sig0, sig1])
        ),
    )

    log.msg(
        "sig0, sig1 by pk0, pk1",
        verification_result=bls.FastAggregateVerify(
            [pk0, pk1], m, bls.Aggregate([sig0, sig1])
        ),
    )
    log.msg(
        "sig0, sig1 by pk0, pk1",
        verification_result=bls.FastAggregateVerify(
            [pk0, pk1], m, bls.Aggregate([sig0, sig1])
        ),
    )

    log.msg(
        "sig0, sig1, sig01 by pk0, pk1",
        verification_result=bls.FastAggregateVerify(
            [pk0, pk1], m, bls.Aggregate([sig0, sig1, sig01])
        ),
    )

    log.msg(
        "sig1 by pk01",
        verification_result=bls.FastAggregateVerify(
            [pk0, pk1], m, bls.Aggregate([sig01])
        ),
    )
    log.msg(
        "AggregateVerify sigm0, sigm1 by pk0, pk1",
        verification_result=bls.AggregateVerify(
            [pk0, pk1], [m0, m1], bls.Aggregate([sigm0, sigm1])
        ),
    )

    log.msg(
        "AggregateVerify sigm0, sigm1 by pk01",
        veriverification_result=bls.AggregateVerify(
            [pk01], [m0, m1], bls.Aggregate([sigm0, sigm1])
        ),
    )

    # Eth2 Proposal Threat model

    # *_someone* deposits 32ETH to the ETH1 deposit contract with a bls PK as it's validator key

    # need to wait a bit to become an _active_ validator

    # All validators update their list of active validator, including _someone to the list at
    # some point

    # *_someone* gets randomly selected as proposer and/or aggregator

    # Is it possible for *_someone* to generate conflicting block proposals with an aggregated
    # signature, that is accepted (=verified to true against some pubkey) but is *not*
    # traceable back to *_someone*

    # Is it possible for *_someone* pubkeys to generate valid proposals as well of *_someone*
    # from subkeys (e.g. aggregated summands)?


def test_partitions_of_1_mod_m():

    moduli = primes(30)
    for modulus in moduli:
        assert is_prime(modulus)
    for modulus in moduli:
        power_set_size = 2 ** modulus
        partition_set_size = 0
        partitions = []
        for k in range(modulus):
            subsets = list(combinations(range(modulus), k))
            for subset in subsets:
                if sum(subset) % modulus == 1:
                    partitions.append(subset)
                    partition_set_size += 1
                    # log.msg("found a partition of unity", length=k, subset=subset)
        partition_ratio = partition_set_size / power_set_size
        mean_partition_length = numpy.mean([len(partition) for partition in partitions])
        median_partition_length = numpy.median(
            [len(partition) for partition in partitions]
        )
        log.msg(
            "Results",
            modulus=modulus,
            power_set_size=power_set_size,
            partition_set_size=partition_set_size,
            median_partition_length=median_partition_length,
            mean_partition_length=mean_partition_length,
            partition_ratio=partition_ratio,
        )


# profile the addition of public keys coming from a (given or randomly generated) set of private keys
def test_sum_pks():
    for i in range(100):
        sks = numpy.random.randint(1, 10 ** 18, 2048)  # 10**18 is the max of numpy randint
        pks = [bls.SkToPk(sk.item()) for sk in sks]
        start = timer()
        sum_pks = bls._AggregatePKs(pks)
        sum_pks_G1 = pubkey_to_G1(sum_pks)
        if eq(sum_pks_G1, G1):
            log.msg("sum is one key", pks=pks, sum_pks=sum_pks)
        elif is_inf(sum_pks_G1):
            log.msg("sum is is_inf key", pks=pks, sum_pks=sum_pks)
        end = timer()
        log.msg(
            "time ",
            verification_result=end - start,
        )
